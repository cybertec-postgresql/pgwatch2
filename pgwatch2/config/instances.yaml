- unique_name: test1  # an arbitrary name for the monitored DB. functions also as prefix for found DBs if using continuous discovery "dbtype"-s
                      # NB! Should be chosen carefully - cannot be (easily) changed for the already stored metric data!
  dbtype: postgres    # postgres|postgres-continuous-discovery|pgbouncer|pgpool|patroni|patroni-continuous-discovery|patroni-namespace-discovery
                      # defaults to postgres if not specified
  host: localhost
  port: 5432          # defaults to 5432 if not specified
  dbname: pgwatch2
  user: someuser
  password: somepass
  sslmode: disable    # supported options: disable, require, verify-ca, verify-full
#  libpq_conn_str: postgresql://user@localhost:5432/postgres  # overrides single connect params. no pwd encryption possible
  stmt_timeout: 5 # in seconds
  is_superuser: false # setting to true will try to auto-create all metric fetching "helpers"
  preset_metrics: minimal # from list of presets defined in "metrics/preset-configs.yaml"
  custom_metrics:    # if both preset and custom are specified, custom wins
  preset_metrics_standby: # optional metrics configuration for standby / replica state, v1.8.1+
  custom_metrics_standby:
  dbname_include_pattern: # regex to filter databases to actually monitor for the "continuous" modes
  dbname_exclude_pattern:
  is_enabled: true
  group: default # just for logical grouping of DB hosts or for "sharding", i.e. splitting the workload between many gatherer daemons
  custom_tags:      # option to add arbitrary tags (Influx / Postgres storage only) for every stored data row,
    aws_instance_id: i-0af01c0123456789a       # for example to fetch data from some other source onto a same Grafana graph
  sslrootcert: ''
  sslcert: ''
  sslkey: ''

- unique_name: test2
  dbtype: patroni-continuous-discovery
  host: localhost
  port: 5432
  dbname: ''
  user: postgres
  password:
  sslmode: disable
  host_config:    # used for storing patroni connect info (dbtype=patroni|patroni-continuous-discovery) or log parsing settings
    dcs_type: etcd
    dcs_endpoints: ["http://localhost:2379"]
    scope: batman
    namespace: /service/
    username:
    password:
    ca_file:
    cert_file:
    key_file:
    logs_glob_path: "/tmp/*.csv"
    logs_match_regex: ^(?P<log_time>.*?),"?(?P<user_name>.*?)"?,"?(?P<database_name>.*?)"?,(?P<process_id>\d+),"?(?P<connection_from>.*?)"?,(?P<session_id>.*?),(?P<session_line_num>\d+),"?(?P<command_tag>.*?)"?,(?P<session_start_time>.*?),(?P<virtual_transaction_id>.*?),(?P<transaction_id>.*?),(?P<error_severity>\w+),
#    logs_match_regex: '^(?P<log_time>.*) \[(?P<process_id>\d+)\] (?P<user_name>.*)@(?P<database_name>.*?) (?P<error_severity>.*?): ' # a sample regex (Debian / Ubuntu default) if not using CSVLOG
  stmt_timeout: 5
  preset_metrics:
  custom_metrics:
    wal: 60
  dbname_include_pattern: (bar|postgres)
  dbname_exclude_pattern:
  is_enabled: false
  only_if_master: true # don't gather metrics from standby servers
